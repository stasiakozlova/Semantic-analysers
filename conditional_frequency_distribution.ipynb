{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Sc0nx8EtE3rJ"
      },
      "outputs": [],
      "source": [
        "#Основные примеры из главны 2 книги по NLTK http://www.nltk.org/book/ch02.html#sec-conditional-frequency-distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpapzLh-E3rR",
        "outputId": "c2daa256-078e-4ace-c94f-b8fa8738b637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Просмотр корпуса (файлы из корпуса проекта Gutenberg)\n",
        "import nltk\n",
        "nltk.corpus.gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzZ7QyChE3rU",
        "outputId": "e166ded0-04f9-4981-d85e-97a81d531f62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "192427"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Выделение текста из корпуса, приписывание ему самостоятельного имени, определение объема в леммах\n",
        "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
        "len(emma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg4bYnWeE3rW",
        "outputId": "a3e01ae2-a010-4718-acda-8ad020d25d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 25 26 austen-emma.txt\n",
            "5 26 17 austen-persuasion.txt\n",
            "5 28 22 austen-sense.txt\n",
            "4 34 79 bible-kjv.txt\n",
            "5 19 5 blake-poems.txt\n",
            "4 19 14 bryant-stories.txt\n",
            "4 18 12 burgess-busterbrown.txt\n",
            "4 20 13 carroll-alice.txt\n",
            "5 20 12 chesterton-ball.txt\n",
            "5 23 11 chesterton-brown.txt\n",
            "5 18 11 chesterton-thursday.txt\n",
            "4 21 25 edgeworth-parents.txt\n",
            "5 26 15 melville-moby_dick.txt\n",
            "5 52 11 milton-paradise.txt\n",
            "4 12 9 shakespeare-caesar.txt\n",
            "4 12 8 shakespeare-hamlet.txt\n",
            "4 12 7 shakespeare-macbeth.txt\n",
            "5 36 12 whitman-leaves.txt\n"
          ]
        }
      ],
      "source": [
        "#Получение статистической информации о текстах корпуса (средняя длина слова, средняя длина предложения, коэффициент лексического разнообразия)\n",
        "from nltk.corpus import gutenberg\n",
        "for fileid in gutenberg.fileids():\n",
        "    num_chars = len(gutenberg.raw(fileid))\n",
        "    num_words = len(gutenberg.words(fileid))\n",
        "    num_sents = len(gutenberg.sents(fileid))\n",
        "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
        "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbYSO5tEE3rY",
        "outputId": "89fce526-3449-44cc-a6b8-328ce7652231"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Выдача рубрик Брауновского корпуса\n",
        "from nltk.corpus import brown\n",
        "brown.categories()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-rNCJIgE3rZ",
        "outputId": "1b8e3bf4-ad0d-4357-c177-205a1a6fd53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "can: 249 could: 216 may: 221 might: 113 must: 171 will: 246 "
          ]
        }
      ],
      "source": [
        "# Определение частоты встречаемости модальных глаголов в новостной рубрике\n",
        "from nltk.corpus import brown\n",
        "news_text = brown.words(categories='belles_lettres')\n",
        "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
        "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
        "for m in modals:\n",
        "    print(m + ':', fdist[m], end=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyBD4V6SE3rb",
        "outputId": "935f3970-2b0a-4036-fe77-e671a1bcacbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "170576"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Определение статистических параметров текстов разных жанров\n",
        "from nltk.corpus import brown\n",
        "сfd = nltk.ConditionalFreqDist(\n",
        "    (genre, word)\n",
        "    for genre in brown.categories()\n",
        "    for word in brown.words(categories=genre))\n",
        "genre_word = [(genre, word)\n",
        "             for genre in ['news', 'romance']\n",
        "             for word in brown.words(categories=genre)]\n",
        "len(genre_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHbp66bdE3rd",
        "outputId": "8cfe4e27-147f-4828-c57b-2910b1acefd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.06230453042623537"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Расчет коэффициента лексического разнообразия\n",
        "from __future__ import division\n",
        "def lexical_diversity(my_text_data):\n",
        "    word_count = len(my_text_data)\n",
        "    vocab_size = len(set(my_text_data))\n",
        "    diversity_score = vocab_size / word_count\n",
        "    return diversity_score\n",
        "from nltk.corpus import genesis\n",
        "kjv = genesis.words('english-kjv.txt')\n",
        "lexical_diversity(kjv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2eT7THbE3re",
        "outputId": "e417079c-2f4a-4fa4-f2d0-bda0781056e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['и',\n",
              " 'в',\n",
              " 'во',\n",
              " 'не',\n",
              " 'что',\n",
              " 'он',\n",
              " 'на',\n",
              " 'я',\n",
              " 'с',\n",
              " 'со',\n",
              " 'как',\n",
              " 'а',\n",
              " 'то',\n",
              " 'все',\n",
              " 'она',\n",
              " 'так',\n",
              " 'его',\n",
              " 'но',\n",
              " 'да',\n",
              " 'ты',\n",
              " 'к',\n",
              " 'у',\n",
              " 'же',\n",
              " 'вы',\n",
              " 'за',\n",
              " 'бы',\n",
              " 'по',\n",
              " 'только',\n",
              " 'ее',\n",
              " 'мне',\n",
              " 'было',\n",
              " 'вот',\n",
              " 'от',\n",
              " 'меня',\n",
              " 'еще',\n",
              " 'нет',\n",
              " 'о',\n",
              " 'из',\n",
              " 'ему',\n",
              " 'теперь',\n",
              " 'когда',\n",
              " 'даже',\n",
              " 'ну',\n",
              " 'вдруг',\n",
              " 'ли',\n",
              " 'если',\n",
              " 'уже',\n",
              " 'или',\n",
              " 'ни',\n",
              " 'быть',\n",
              " 'был',\n",
              " 'него',\n",
              " 'до',\n",
              " 'вас',\n",
              " 'нибудь',\n",
              " 'опять',\n",
              " 'уж',\n",
              " 'вам',\n",
              " 'ведь',\n",
              " 'там',\n",
              " 'потом',\n",
              " 'себя',\n",
              " 'ничего',\n",
              " 'ей',\n",
              " 'может',\n",
              " 'они',\n",
              " 'тут',\n",
              " 'где',\n",
              " 'есть',\n",
              " 'надо',\n",
              " 'ней',\n",
              " 'для',\n",
              " 'мы',\n",
              " 'тебя',\n",
              " 'их',\n",
              " 'чем',\n",
              " 'была',\n",
              " 'сам',\n",
              " 'чтоб',\n",
              " 'без',\n",
              " 'будто',\n",
              " 'чего',\n",
              " 'раз',\n",
              " 'тоже',\n",
              " 'себе',\n",
              " 'под',\n",
              " 'будет',\n",
              " 'ж',\n",
              " 'тогда',\n",
              " 'кто',\n",
              " 'этот',\n",
              " 'того',\n",
              " 'потому',\n",
              " 'этого',\n",
              " 'какой',\n",
              " 'совсем',\n",
              " 'ним',\n",
              " 'здесь',\n",
              " 'этом',\n",
              " 'один',\n",
              " 'почти',\n",
              " 'мой',\n",
              " 'тем',\n",
              " 'чтобы',\n",
              " 'нее',\n",
              " 'сейчас',\n",
              " 'были',\n",
              " 'куда',\n",
              " 'зачем',\n",
              " 'всех',\n",
              " 'никогда',\n",
              " 'можно',\n",
              " 'при',\n",
              " 'наконец',\n",
              " 'два',\n",
              " 'об',\n",
              " 'другой',\n",
              " 'хоть',\n",
              " 'после',\n",
              " 'над',\n",
              " 'больше',\n",
              " 'тот',\n",
              " 'через',\n",
              " 'эти',\n",
              " 'нас',\n",
              " 'про',\n",
              " 'всего',\n",
              " 'них',\n",
              " 'какая',\n",
              " 'много',\n",
              " 'разве',\n",
              " 'три',\n",
              " 'эту',\n",
              " 'моя',\n",
              " 'впрочем',\n",
              " 'хорошо',\n",
              " 'свою',\n",
              " 'этой',\n",
              " 'перед',\n",
              " 'иногда',\n",
              " 'лучше',\n",
              " 'чуть',\n",
              " 'том',\n",
              " 'нельзя',\n",
              " 'такой',\n",
              " 'им',\n",
              " 'более',\n",
              " 'всегда',\n",
              " 'конечно',\n",
              " 'всю',\n",
              " 'между']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод стоп-словаря\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfj_KunzE3rh",
        "outputId": "da75d97b-4814-495a-85c2-170252996d31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.735240435097661"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Расчет доли значимых слов\n",
        "def content_fraction(text):\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    content = [w for w in text if w.lower() not in stopwords]\n",
        "    return len(content) / len(text)\n",
        "content_fraction(nltk.corpus.reuters.words())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHkZidBrE3rj",
        "outputId": "e57f9f6c-9863-4c70-da55-a81229f30a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['glover',\n",
              " 'gorlin',\n",
              " 'govern',\n",
              " 'grovel',\n",
              " 'ignore',\n",
              " 'involver',\n",
              " 'lienor',\n",
              " 'linger',\n",
              " 'longer',\n",
              " 'lovering',\n",
              " 'noiler',\n",
              " 'overling',\n",
              " 'region',\n",
              " 'renvoi',\n",
              " 'revolving',\n",
              " 'ringle',\n",
              " 'roving',\n",
              " 'violer',\n",
              " 'virole']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Возможные осмысленные комбинации букв\n",
        "puzzle_letters = nltk.FreqDist('egivrvonl')\n",
        "obligatory = 'r'\n",
        "wordlist = nltk.corpus.words.words()\n",
        "[w for w in wordlist if len(w) >= 6\n",
        "                      and obligatory in w\n",
        "                      and nltk.FreqDist(w) <= puzzle_letters]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7QCKkMtE3rk",
        "outputId": "c3694da3-9684-4a76-cfce-00ce02143977"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Abbey',\n",
              " 'Abbie',\n",
              " 'Abby',\n",
              " 'Addie',\n",
              " 'Adrian',\n",
              " 'Adrien',\n",
              " 'Ajay',\n",
              " 'Alex',\n",
              " 'Alexis',\n",
              " 'Alfie',\n",
              " 'Ali',\n",
              " 'Alix',\n",
              " 'Allie',\n",
              " 'Allyn',\n",
              " 'Andie',\n",
              " 'Andrea',\n",
              " 'Andy',\n",
              " 'Angel',\n",
              " 'Angie',\n",
              " 'Ariel',\n",
              " 'Ashley',\n",
              " 'Aubrey',\n",
              " 'Augustine',\n",
              " 'Austin',\n",
              " 'Averil',\n",
              " 'Barrie',\n",
              " 'Barry',\n",
              " 'Beau',\n",
              " 'Bennie',\n",
              " 'Benny',\n",
              " 'Bernie',\n",
              " 'Bert',\n",
              " 'Bertie',\n",
              " 'Bill',\n",
              " 'Billie',\n",
              " 'Billy',\n",
              " 'Blair',\n",
              " 'Blake',\n",
              " 'Bo',\n",
              " 'Bobbie',\n",
              " 'Bobby',\n",
              " 'Brandy',\n",
              " 'Brett',\n",
              " 'Britt',\n",
              " 'Brook',\n",
              " 'Brooke',\n",
              " 'Brooks',\n",
              " 'Bryn',\n",
              " 'Cal',\n",
              " 'Cam',\n",
              " 'Cammy',\n",
              " 'Carey',\n",
              " 'Carlie',\n",
              " 'Carlin',\n",
              " 'Carmine',\n",
              " 'Carroll',\n",
              " 'Cary',\n",
              " 'Caryl',\n",
              " 'Casey',\n",
              " 'Cass',\n",
              " 'Cat',\n",
              " 'Cecil',\n",
              " 'Chad',\n",
              " 'Chris',\n",
              " 'Chrissy',\n",
              " 'Christian',\n",
              " 'Christie',\n",
              " 'Christy',\n",
              " 'Clair',\n",
              " 'Claire',\n",
              " 'Clare',\n",
              " 'Claude',\n",
              " 'Clem',\n",
              " 'Clemmie',\n",
              " 'Cody',\n",
              " 'Connie',\n",
              " 'Constantine',\n",
              " 'Corey',\n",
              " 'Corrie',\n",
              " 'Cory',\n",
              " 'Courtney',\n",
              " 'Cris',\n",
              " 'Daffy',\n",
              " 'Dale',\n",
              " 'Dallas',\n",
              " 'Dana',\n",
              " 'Dani',\n",
              " 'Daniel',\n",
              " 'Dannie',\n",
              " 'Danny',\n",
              " 'Darby',\n",
              " 'Darcy',\n",
              " 'Darryl',\n",
              " 'Daryl',\n",
              " 'Deane',\n",
              " 'Del',\n",
              " 'Dell',\n",
              " 'Demetris',\n",
              " 'Dennie',\n",
              " 'Denny',\n",
              " 'Devin',\n",
              " 'Devon',\n",
              " 'Dion',\n",
              " 'Dionis',\n",
              " 'Dominique',\n",
              " 'Donnie',\n",
              " 'Donny',\n",
              " 'Dorian',\n",
              " 'Dory',\n",
              " 'Drew',\n",
              " 'Eddie',\n",
              " 'Eddy',\n",
              " 'Edie',\n",
              " 'Elisha',\n",
              " 'Emmy',\n",
              " 'Erin',\n",
              " 'Esme',\n",
              " 'Evelyn',\n",
              " 'Felice',\n",
              " 'Fran',\n",
              " 'Francis',\n",
              " 'Frank',\n",
              " 'Frankie',\n",
              " 'Franky',\n",
              " 'Fred',\n",
              " 'Freddie',\n",
              " 'Freddy',\n",
              " 'Gabriel',\n",
              " 'Gabriell',\n",
              " 'Gail',\n",
              " 'Gale',\n",
              " 'Gay',\n",
              " 'Gayle',\n",
              " 'Gene',\n",
              " 'George',\n",
              " 'Georgia',\n",
              " 'Georgie',\n",
              " 'Geri',\n",
              " 'Germaine',\n",
              " 'Gerri',\n",
              " 'Gerry',\n",
              " 'Gill',\n",
              " 'Ginger',\n",
              " 'Glen',\n",
              " 'Glenn',\n",
              " 'Grace',\n",
              " 'Gretchen',\n",
              " 'Gus',\n",
              " 'Haleigh',\n",
              " 'Haley',\n",
              " 'Hannibal',\n",
              " 'Harley',\n",
              " 'Hazel',\n",
              " 'Heath',\n",
              " 'Henrie',\n",
              " 'Hilary',\n",
              " 'Hillary',\n",
              " 'Holly',\n",
              " 'Ike',\n",
              " 'Ikey',\n",
              " 'Ira',\n",
              " 'Isa',\n",
              " 'Isador',\n",
              " 'Isadore',\n",
              " 'Jackie',\n",
              " 'Jaime',\n",
              " 'Jamie',\n",
              " 'Jan',\n",
              " 'Jean',\n",
              " 'Jere',\n",
              " 'Jermaine',\n",
              " 'Jerrie',\n",
              " 'Jerry',\n",
              " 'Jess',\n",
              " 'Jesse',\n",
              " 'Jessie',\n",
              " 'Jo',\n",
              " 'Jodi',\n",
              " 'Jodie',\n",
              " 'Jody',\n",
              " 'Joey',\n",
              " 'Jordan',\n",
              " 'Juanita',\n",
              " 'Jude',\n",
              " 'Judith',\n",
              " 'Judy',\n",
              " 'Julie',\n",
              " 'Justin',\n",
              " 'Karel',\n",
              " 'Kellen',\n",
              " 'Kelley',\n",
              " 'Kelly',\n",
              " 'Kelsey',\n",
              " 'Kerry',\n",
              " 'Kim',\n",
              " 'Kip',\n",
              " 'Kirby',\n",
              " 'Kit',\n",
              " 'Kris',\n",
              " 'Kyle',\n",
              " 'Lane',\n",
              " 'Lanny',\n",
              " 'Lauren',\n",
              " 'Laurie',\n",
              " 'Lee',\n",
              " 'Leigh',\n",
              " 'Leland',\n",
              " 'Lesley',\n",
              " 'Leslie',\n",
              " 'Lin',\n",
              " 'Lind',\n",
              " 'Lindsay',\n",
              " 'Lindsey',\n",
              " 'Lindy',\n",
              " 'Lonnie',\n",
              " 'Loren',\n",
              " 'Lorne',\n",
              " 'Lorrie',\n",
              " 'Lou',\n",
              " 'Luce',\n",
              " 'Lyn',\n",
              " 'Lynn',\n",
              " 'Maddie',\n",
              " 'Maddy',\n",
              " 'Marietta',\n",
              " 'Marion',\n",
              " 'Marlo',\n",
              " 'Martie',\n",
              " 'Marty',\n",
              " 'Mattie',\n",
              " 'Matty',\n",
              " 'Maurise',\n",
              " 'Max',\n",
              " 'Maxie',\n",
              " 'Mead',\n",
              " 'Meade',\n",
              " 'Mel',\n",
              " 'Meredith',\n",
              " 'Merle',\n",
              " 'Merrill',\n",
              " 'Merry',\n",
              " 'Meryl',\n",
              " 'Michal',\n",
              " 'Michel',\n",
              " 'Michele',\n",
              " 'Mickie',\n",
              " 'Micky',\n",
              " 'Millicent',\n",
              " 'Morgan',\n",
              " 'Morlee',\n",
              " 'Muffin',\n",
              " 'Nat',\n",
              " 'Nichole',\n",
              " 'Nickie',\n",
              " 'Nicky',\n",
              " 'Niki',\n",
              " 'Nikki',\n",
              " 'Noel',\n",
              " 'Ollie',\n",
              " 'Page',\n",
              " 'Paige',\n",
              " 'Pat',\n",
              " 'Patrice',\n",
              " 'Patsy',\n",
              " 'Pattie',\n",
              " 'Patty',\n",
              " 'Pen',\n",
              " 'Pennie',\n",
              " 'Penny',\n",
              " 'Perry',\n",
              " 'Phil',\n",
              " 'Pooh',\n",
              " 'Quentin',\n",
              " 'Quinn',\n",
              " 'Randi',\n",
              " 'Randie',\n",
              " 'Randy',\n",
              " 'Ray',\n",
              " 'Regan',\n",
              " 'Reggie',\n",
              " 'Rene',\n",
              " 'Rey',\n",
              " 'Ricki',\n",
              " 'Rickie',\n",
              " 'Ricky',\n",
              " 'Rikki',\n",
              " 'Robbie',\n",
              " 'Robin',\n",
              " 'Ronnie',\n",
              " 'Ronny',\n",
              " 'Rory',\n",
              " 'Ruby',\n",
              " 'Sal',\n",
              " 'Sam',\n",
              " 'Sammy',\n",
              " 'Sandy',\n",
              " 'Sascha',\n",
              " 'Sasha',\n",
              " 'Saundra',\n",
              " 'Sayre',\n",
              " 'Scotty',\n",
              " 'Sean',\n",
              " 'Shaine',\n",
              " 'Shane',\n",
              " 'Shannon',\n",
              " 'Shaun',\n",
              " 'Shawn',\n",
              " 'Shay',\n",
              " 'Shayne',\n",
              " 'Shea',\n",
              " 'Shelby',\n",
              " 'Shell',\n",
              " 'Shelley',\n",
              " 'Sibyl',\n",
              " 'Simone',\n",
              " 'Sonnie',\n",
              " 'Sonny',\n",
              " 'Stacy',\n",
              " 'Sunny',\n",
              " 'Sydney',\n",
              " 'Tabbie',\n",
              " 'Tabby',\n",
              " 'Tallie',\n",
              " 'Tally',\n",
              " 'Tammie',\n",
              " 'Tammy',\n",
              " 'Tate',\n",
              " 'Ted',\n",
              " 'Teddie',\n",
              " 'Teddy',\n",
              " 'Terri',\n",
              " 'Terry',\n",
              " 'Theo',\n",
              " 'Tim',\n",
              " 'Timmie',\n",
              " 'Timmy',\n",
              " 'Tobe',\n",
              " 'Tobie',\n",
              " 'Toby',\n",
              " 'Tommie',\n",
              " 'Tommy',\n",
              " 'Tony',\n",
              " 'Torey',\n",
              " 'Trace',\n",
              " 'Tracey',\n",
              " 'Tracie',\n",
              " 'Tracy',\n",
              " 'Val',\n",
              " 'Vale',\n",
              " 'Valentine',\n",
              " 'Van',\n",
              " 'Vin',\n",
              " 'Vinnie',\n",
              " 'Vinny',\n",
              " 'Virgie',\n",
              " 'Wallie',\n",
              " 'Wallis',\n",
              " 'Wally',\n",
              " 'Whitney',\n",
              " 'Willi',\n",
              " 'Willie',\n",
              " 'Willy',\n",
              " 'Winnie',\n",
              " 'Winny',\n",
              " 'Wynn']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Имена собственные (M&F)\n",
        "names = nltk.corpus.names\n",
        "names.fileids()\n",
        "['female.txt', 'male.txt']\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "[w for w in male_names if w in female_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NGNnNxeE3rl",
        "outputId": "0a39e0ec-78f0-41bc-8d25-b23abcdd0601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['be',\n",
              " 'bg',\n",
              " 'bs',\n",
              " 'ca',\n",
              " 'cs',\n",
              " 'cu',\n",
              " 'de',\n",
              " 'en',\n",
              " 'es',\n",
              " 'fr',\n",
              " 'hr',\n",
              " 'it',\n",
              " 'la',\n",
              " 'mk',\n",
              " 'nl',\n",
              " 'pl',\n",
              " 'pt',\n",
              " 'ro',\n",
              " 'ru',\n",
              " 'sk',\n",
              " 'sl',\n",
              " 'sr',\n",
              " 'sw',\n",
              " 'uk']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Работа со списком Сводеша\n",
        "from nltk.corpus import swadesh\n",
        "swadesh.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXHL9o9oE3rm",
        "outputId": "c7ac6b3b-93c4-4a6b-c467-7c0bed0d9912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dog'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Поиск переводных эквивалентов по списку Сводеша\n",
        "fr2en = swadesh.entries(['fr', 'en'])\n",
        "fr2en\n",
        "[('je', 'I'), ('tu, vous', 'you (singular), thou'), ('il', 'he'), ...]\n",
        "translate = dict(fr2en)\n",
        "translate['chien']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20qUkA_LE3rn",
        "outputId": "fc2d9ed0-b7d2-455b-a945-50bb1eb6f421"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('car.n.01')]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вызов WordNet и извлечение синсетов\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synsets('motorcar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYQpIgeiE3ro",
        "outputId": "7ebb1cd2-be2f-426f-de96-10f3f7b2d2f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['car', 'auto', 'automobile', 'machine', 'motorcar']"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Состав синсетов\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synset('car.n.01').lemma_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqZtGKqQE3rp",
        "outputId": "7ae07447-5f1e-4377-a78f-c53b83b61c90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод определения\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synset('car.n.01').definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOh71M6aE3rq",
        "outputId": "a8264d94-006a-4b42-e4ad-f18e83967ac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['he needs a car to get to work']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод примеров\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synset('car.n.01').examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK9i0swsE3rq",
        "outputId": "602e02a6-1baf-432a-8b48-80d8f7460187"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('car.n.01'),\n",
              " Synset('car.n.02'),\n",
              " Synset('car.n.03'),\n",
              " Synset('car.n.04'),\n",
              " Synset('cable_car.n.01')]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод информации о синсетах для разных значений леммы\n",
        "wn.synsets('car')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8qwkacME3rr",
        "outputId": "3fdfa04e-26ba-4467-f4f1-8794daeaeac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
            "['car', 'railcar', 'railway_car', 'railroad_car']\n",
            "['car', 'gondola']\n",
            "['car', 'elevator_car']\n",
            "['cable_car', 'car']\n"
          ]
        }
      ],
      "source": [
        "#Вывод состава синсетов для разных значений леммы\n",
        "wn.synsets('car')\n",
        "for synset in wn.synsets('car'):\n",
        "     print(synset.lemma_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q2HKhS-E3rs",
        "outputId": "9de7a925-c345-4a85-f93c-c1eec3c3b489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Synset('ambulance.n.01')"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод синсета гипонимов\n",
        "motorcar = wn.synset('car.n.01')\n",
        "types_of_motorcar = motorcar.hyponyms()\n",
        "types_of_motorcar[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD96bXU9E3rs",
        "outputId": "cf8c17fe-304b-42c1-e75f-db6130c5d9be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Model_T',\n",
              " 'S.U.V.',\n",
              " 'SUV',\n",
              " 'Stanley_Steamer',\n",
              " 'ambulance',\n",
              " 'beach_waggon',\n",
              " 'beach_wagon',\n",
              " 'bus',\n",
              " 'cab',\n",
              " 'compact',\n",
              " 'compact_car',\n",
              " 'convertible',\n",
              " 'coupe',\n",
              " 'cruiser',\n",
              " 'electric',\n",
              " 'electric_automobile',\n",
              " 'electric_car',\n",
              " 'estate_car',\n",
              " 'gas_guzzler',\n",
              " 'hack',\n",
              " 'hardtop',\n",
              " 'hatchback',\n",
              " 'heap',\n",
              " 'horseless_carriage',\n",
              " 'hot-rod',\n",
              " 'hot_rod',\n",
              " 'jalopy',\n",
              " 'jeep',\n",
              " 'landrover',\n",
              " 'limo',\n",
              " 'limousine',\n",
              " 'loaner',\n",
              " 'minicar',\n",
              " 'minivan',\n",
              " 'pace_car',\n",
              " 'patrol_car',\n",
              " 'phaeton',\n",
              " 'police_car',\n",
              " 'police_cruiser',\n",
              " 'prowl_car',\n",
              " 'race_car',\n",
              " 'racer',\n",
              " 'racing_car',\n",
              " 'roadster',\n",
              " 'runabout',\n",
              " 'saloon',\n",
              " 'secondhand_car',\n",
              " 'sedan',\n",
              " 'sport_car',\n",
              " 'sport_utility',\n",
              " 'sport_utility_vehicle',\n",
              " 'sports_car',\n",
              " 'squad_car',\n",
              " 'station_waggon',\n",
              " 'station_wagon',\n",
              " 'stock_car',\n",
              " 'subcompact',\n",
              " 'subcompact_car',\n",
              " 'taxi',\n",
              " 'taxicab',\n",
              " 'tourer',\n",
              " 'touring_car',\n",
              " 'two-seater',\n",
              " 'used-car',\n",
              " 'waggon',\n",
              " 'wagon']"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Развернутый список гипонимов\n",
        "types_of_motorcar = motorcar.hyponyms()\n",
        "types_of_motorcar[0]\n",
        "sorted(lemma.name() for synset in types_of_motorcar for lemma in synset.lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PIs0cbQE3rt",
        "outputId": "56ec5f81-f9cf-4d72-aa37-fe07c03738b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('motor_vehicle.n.01')]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод гиперонимов\n",
        "motorcar.hypernyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipjCbqghE3ru",
        "outputId": "55b2dc5f-4d0f-4f89-f8d2-87c737a81253"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['entity.n.01',\n",
              " 'physical_entity.n.01',\n",
              " 'object.n.01',\n",
              " 'whole.n.02',\n",
              " 'artifact.n.01',\n",
              " 'instrumentality.n.03',\n",
              " 'container.n.01',\n",
              " 'wheeled_vehicle.n.01',\n",
              " 'self-propelled_vehicle.n.01',\n",
              " 'motor_vehicle.n.01',\n",
              " 'car.n.01']"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Развернутые данные о гипонимах\n",
        "motorcar.hypernyms()\n",
        "paths = motorcar.hypernym_paths()\n",
        "len(paths)\n",
        "2\n",
        "[synset.name() for synset in paths[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEfjw8fjE3ru",
        "outputId": "e4416e0b-5022-478c-f33a-5b8395f7abb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('burl.n.02'),\n",
              " Synset('crown.n.07'),\n",
              " Synset('limb.n.02'),\n",
              " Synset('stump.n.01'),\n",
              " Synset('trunk.n.01')]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод меронимов 1\n",
        "wn.synset('tree.n.01').part_meronyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLWM03bhE3rv",
        "outputId": "296cf3c6-4731-4fbb-f979-e92066336294"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('heartwood.n.01'), Synset('sapwood.n.01')]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод меронимов 2\n",
        "wn.synset('tree.n.01').substance_meronyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuopjHZLE3rv",
        "outputId": "a56579b4-cbce-41f0-bed7-0d022cfd9663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('forest.n.01')]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод холонимов\n",
        "wn.synset('tree.n.01').member_holonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqw9JzMyE3rw",
        "outputId": "c9f3c8a4-8181-40f2-f005-6ce7f71cf1e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('step.v.01')]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Отношения логического вывода\n",
        "wn.synset('walk.v.01').entailments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVf412k3E3rx",
        "outputId": "6633822f-2d2d-4b5a-e13e-4a2f958c0e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('demand.n.02.demand')]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Вывод антонимов\n",
        "wn.lemma('supply.n.02.supply').antonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDL-NjPXE3rx",
        "outputId": "63796438-6848-4f86-ecd1-4ac3d18739bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('baleen_whale.n.01')]"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Определение расстояний в WN\n",
        "right = wn.synset('right_whale.n.01')\n",
        "orca = wn.synset('orca.n.01')\n",
        "minke = wn.synset('minke_whale.n.01')\n",
        "tortoise = wn.synset('tortoise.n.01')\n",
        "novel = wn.synset('novel.n.01')\n",
        "right.lowest_common_hypernyms(minke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wg7BDjME3ry",
        "outputId": "fd824d15-1e12-4feb-8658-6a21f2a108a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Расчет глубины синсета\n",
        "wn.synset('baleen_whale.n.01').min_depth()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJOj3Q1hE3ry",
        "outputId": "e583ed47-fb99-4389-a9c2-ed7a9a67fa47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<PropbankInstance: wsj_0001.mrg, sent 0, word 8>, <PropbankInstance: wsj_0001.mrg, sent 1, word 10>, ...]\n"
          ]
        }
      ],
      "source": [
        "# Обращение к PropBank\n",
        "from nltk.corpus import propbank\n",
        "pb_instances = propbank.instances()\n",
        "print(pb_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFHNz4fQE3rz",
        "outputId": "4cc6541a-4950-417e-b551-08f13e26cae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wsj_0001.mrg 0 8 gold join.01 vf--a 0:2-ARG0 7:0-ARGM-MOD 8:0-rel 9:1-ARG1 11:1-ARGM-PRD 15:1-ARGM-TMP\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import propbank\n",
        "# Вывод аннотации глагола join\n",
        "print(propbank.instances()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy9EnZtpE3rz",
        "outputId": "25f50dac-7579-40f1-9b0c-5535ad97473a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wsj_0003.mrg 15 19 gold say.01 vp--a 1:2*20:0-ARG1 19:0-rel 21:1-ARG0\n",
            "wsj_0004.mrg 8 16 gold rise.01 vp--a 0:2-ARG1 13:1-ARGM-DIS 16:0-rel 17:1-ARG4-to 20:1-ARG3-from\n"
          ]
        }
      ],
      "source": [
        "pb_instances = propbank.instances()\n",
        "print(pb_instances[42])      # Вывод аннотации глагола say\n",
        "print(pb_instances[103])     # Вывод аннотации глагола rise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADyTJCopE3r1",
        "outputId": "6b015cb4-3b7b-42b4-e2d2-0a155d326899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Element 'roleset' at 0x7f7ecdbf9138>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "propbank.roleset('join.01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HpXfqPjE3r1",
        "outputId": "6d8dedb9-5098-47f8-f4a4-a81709fd1f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 agent, entity doing the tying\n",
            "1 patient, thing(s) being tied\n",
            "2 instrument, string\n"
          ]
        }
      ],
      "source": [
        "# Вывод рамки валентностей глагола join c описанием актантов\n",
        "for role in propbank.roleset('join.01').findall('roles/role'):\n",
        "    print(role.attrib['n'], role.attrib['descr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyDCw0rNE3r2",
        "outputId": "edbec1d2-fe40-4172-c89d-797d7ee15e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Logical subject, patient, thing rising\n",
            "2 EXT, amount risen\n",
            "3 start point\n",
            "4 end point\n",
            "M medium\n"
          ]
        }
      ],
      "source": [
        "# Вывод рамки валентностей глагола rise c описанием актантов\n",
        "rise01 = propbank.roleset('rise.01')\n",
        "\n",
        "for role in rise01.findall(\"roles/role\"):\n",
        "    print(role.attrib['n'], role.attrib['descr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhG2_XnlE3r3",
        "outputId": "5e5b66f5-8e9f-42ab-d313-c95ca15a139e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wsj_0001.mrg 0 8 gold join.01 vf--a 0:2-ARG0 7:0-ARGM-MOD 8:0-rel 9:1-ARG1 11:1-ARGM-PRD 15:1-ARGM-TMP\n",
            "wsj_0001.mrg 0 8\n"
          ]
        }
      ],
      "source": [
        "inst0 = pb_instances[0]\n",
        "\n",
        "print(inst0)\n",
        "print(inst0.fileid, inst0.sentnum, inst0.wordnum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvKfBu8vE3r3",
        "outputId": "8c8fde3d-1e39-446b-995d-030b8808a324"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PropbankTreePointer(8, 0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inst0.predicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFtlTUPsE3r3",
        "outputId": "bcbbaa6a-671f-48c0-dd89-dc23a47d222e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(VB join)\n"
          ]
        }
      ],
      "source": [
        "print(inst0.predicate.select(inst0.tree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpnCgmkOE3r4",
        "outputId": "a3bd407c-e4a9-44ce-f260-c4ba60eb1a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ARG0\n",
            "(NP-SBJ\n",
            "  (NP (NNP Pierre) (NNP Vinken))\n",
            "  (, ,)\n",
            "  (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
            "  (, ,))\n",
            "\n",
            "ARGM-MOD\n",
            "(MD will)\n",
            "\n",
            "ARG1\n",
            "(NP (DT the) (NN board))\n",
            "\n",
            "ARGM-PRD\n",
            "(PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
            "\n",
            "ARGM-TMP\n",
            "(NP-TMP (NNP Nov.) (CD 29))\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# вывод куста со связями для актанта\n",
        "for (argloc, argid) in inst0.arguments:\n",
        "    print(argid)\n",
        "    print(argloc.select(inst0.tree))\n",
        "    print()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Козлова_NLTK_trial_Ch2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}